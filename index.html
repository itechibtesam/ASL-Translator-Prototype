<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>ASL Translator Prototype - Mobile Ready</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600;700&display=swap" rel="stylesheet">
    
    <style>
        /* 1. Global & Background (Updated for Mobile Viewport) */
        body {
            margin: 0;
            overflow: hidden;
            background: #000000;
            font-family: 'Poppins', sans-serif;
            color: #E0E0E0;
            /* Ensures full coverage on mobile */
            width: 100vw; 
            height: 100vh;
        }
        video { display: none; }
        
        /* Ensures the canvas takes up the full screen */
        canvas {
            display: block;
            width: 100vw;
            height: 100vh;
            position: fixed;
            top: 0;
            left: 0;
        }

        /* 2. GUI Panel (Centralized Frosted Glass - Adjusted for smaller screens) */
        #gui {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 90%; /* Use percentage for mobile responsiveness */
            max-width: 400px; /* Max width constraint */
            z-index: 100;
            padding: 30px;
            border-radius: 20px; 
            background: rgba(255, 255, 255, 0.1); 
            border: 1px solid rgba(255, 255, 255, 0.2); 
            box-shadow: 0 8px 32px 0 rgba(0, 0, 0, 0.37); 
            backdrop-filter: blur(10px); 
            -webkit-backdrop-filter: blur(10px);
            /* Allows touch events to pass through to elements like the dropdown, but not the background */
            pointer-events: none; 
        }
        
        /* Ensure all interactive elements inside GUI are tappable */
        #voice-selector-container, #voice-select {
            pointer-events: auto; 
        }

        h3 {
            font-size: 1.6em; /* Slightly smaller for mobile */
            font-weight: 700; 
            color: #4CAF50;
            margin-top: 0;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1); 
        }

        /* Instruction List Styling */
        .instructions-heading {
            font-weight: 600;
            margin-bottom: 5px;
            color: #A9A9A9;
        }

        ul {
            list-style: disc; 
            padding-left: 20px;
            margin-bottom: 30px;
            font-weight: 300;
            line-height: 1.6;
        }
        
        ul li {
            margin-bottom: 8px;
        }
        
        /* Status Section Styling */
        .status-line {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 10px;
            font-weight: 400;
        }

        /* 3. Status Indicators */
        .status { 
            color: #FFC107; 
            font-weight: 600;
        }
        
        .recognized { 
            color: #4CAF50; 
            font-weight: 600;
        }
        
        .unclear { 
            color: #FF5252;
            font-weight: 600;
        }

        /* 4. Primary Output Text */
        #output-text {
            font-size: 1.8em; /* Slightly smaller for mobile */
            font-weight: 700;
            color: #00FFFF;
            text-align: center;
            background: rgba(0, 0, 0, 0.4);
            padding: 15px;
            border-radius: 10px;
            margin-top: 20px;
            min-height: 1.2em;
            text-shadow: 0 0 15px rgba(0, 255, 255, 0.5); 
        }

        /* 5. Voice Selector Styling */
        #voice-selector-container {
            margin-bottom: 20px;
            padding-top: 10px;
            border-top: 1px solid rgba(255, 255, 255, 0.1);
        }

        #voice-select {
            width: 100%;
            padding: 10px;
            font-family: 'Poppins', sans-serif;
            font-size: 1em;
            font-weight: 500;
            color: #E0E0E0;
            background: rgba(255, 255, 255, 0.15); 
            border: 1px solid rgba(255, 255, 255, 0.3);
            border-radius: 8px;
            appearance: none; 
        }
        #voice-select option {
            background: #0d1117; 
            color: #E0E0E0;
        }
    </style>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>
</head>
<body>

    <div id="gui">
        <h3>Sign to Speech Translator</h3>

        <div id="voice-selector-container">
            <label for="voice-select" style="font-size: 0.9em; font-weight: 300;">Select Voice:</label>
            <select id="voice-select">
                <option value="default" disabled>Loading Voices...</option>
            </select>
        </div>

        <div class="instructions-heading">Operation Instructions:</div>
        <ul>
            <li>Open Hand: System starts the listening process.</li>
            <li>Hold Sign: System attempts to stabilize and recognize the sign.</li>
            <li>Pinch/Close: Confirms the recognized sign and speaks the translation.</li>
        </ul>

        <div class="status-line">
            System State: <span id="system-status" class="status">Loading Camera...</span>
        </div>
        
        <div class="status-line">
            Current Sign: <span id="current-sign" class="unclear">Waiting...</span>
        </div>

        <div id="output-text"></div>
    </div>
    
    <video id="input_video"></video>

    <script>
        // --- CONFIGURATION & CONSTANTS ---
        const PARTICLE_COUNT = 5000;
        const CAM_WIDTH = 640;
        const CAM_HEIGHT = 480;
        const RECOGNITION_HOLD_TIME = 800; // ms
        const CONFIRM_GESTURE_THRESHOLD = 0.05;

        // Landmark indices for geometry checks
        const L_THUMB_TIP = 4;
        const L_INDEX_TIP = 8;
        const L_MIDDLE_TIP = 12;
        const L_RING_TIP = 16;
        const L_PINKY_TIP = 20;

        // --- GLOBAL STATE ---
        let handLandmarks = null;
        let isHandPresent = false;
        let pinchDistance = 1.0;
        let recognizedSign = 'Unclear';
        let lastStableSign = 'Unclear';
        let confidenceLevel = 0.0;
        let recognitionTimer = null;
        let isSpeaking = false;
        let currentShapeTarget = 'sphere'; 
        
        // --- VOICE STATE ---
        let selectedVoice = null;
        let availableVoices = [];
        let maleVoiceData = null; 
        let femaleVoiceData = null; 


        // --- DOM Elements ---
        const statusEl = document.getElementById('system-status');
        const signEl = document.getElementById('current-sign');
        const outputEl = document.getElementById('output-text');
        const voiceSelect = document.getElementById('voice-select');


        // --- VOICE SETUP ---
        const synth = window.speechSynthesis;
        let lastSpokenText = '';

        /**
         * Finds a distinct English voice prioritizing common male/female names.
         */
        function findVoice(voices, gender, excludeVoiceName = null) {
            const enVoices = voices.filter(v => 
                v.lang.startsWith('en') && 
                v.name !== excludeVoiceName
            );
            
            const lowQualityKeywords = ['compact', 'chrome', 'eloquence'];
            
            // Common high-quality names for gender distinction (Mac/Windows/Google)
            const genderKeywords = gender === 'male' 
                ? ['male', 'mark', 'daniel', 'david', 'lee', 'zack', 'scott'] 
                : ['female', 'samantha', 'serena', 'zira', 'fiona', 'tara', 'ava', 'woman'];

            // 1. Prioritize names matching gender keywords, excluding low quality/compact versions
            let voice = enVoices.find(v => 
                genderKeywords.some(key => v.name.toLowerCase().includes(key)) && 
                !lowQualityKeywords.some(key => v.name.toLowerCase().includes(key))
            );

            // 2. Fallback to any voice with the gender keyword (e.g., "Google US English Male")
            if (!voice) {
                voice = enVoices.find(v => genderKeywords.some(key => v.name.toLowerCase().includes(key)));
            }
            
            // 3. Last resort: just pick the first available voice that hasn't been used
            if (!voice && enVoices.length > 0) {
                 voice = enVoices[0];
            }

            return voice;
        }


        function populateVoiceList() {
            availableVoices = synth.getVoices();
            voiceSelect.innerHTML = ''; 

            // 1. Find the best Male voice
            maleVoiceData = findVoice(availableVoices, 'male');
            
            // 2. Find the best Female voice, excluding the Male voice name
            femaleVoiceData = findVoice(availableVoices, 'female', maleVoiceData ? maleVoiceData.name : null);

            // FALLBACK: If we couldn't find distinct names, force the selection of the first two available unique English voices
            if (!maleVoiceData && availableVoices.filter(v => v.lang.startsWith('en')).length >= 1) {
                maleVoiceData = availableVoices.filter(v => v.lang.startsWith('en'))[0];
            }
            if (!femaleVoiceData && maleVoiceData) {
                femaleVoiceData = availableVoices.filter(v => v.lang.startsWith('en') && v.name !== maleVoiceData.name)[0];
            }


            if (!maleVoiceData) {
                 voiceSelect.innerHTML = '<option value="default" disabled>No English Voices Found</option>';
                 return;
            }

            // --- 1. Add Male Voice Option ---
            const maleOption = document.createElement('option');
            maleOption.value = maleVoiceData.name; 
            maleOption.textContent = `Male Voice: ${maleVoiceData.name}`;
            voiceSelect.appendChild(maleOption);
            
            // Set male as default
            selectedVoice = maleVoiceData;

            // --- 2. Add Female Voice Option ---
            if (femaleVoiceData && femaleVoiceData.name !== maleVoiceData.name) {
                const femaleOption = document.createElement('option');
                femaleOption.value = femaleVoiceData.name;
                femaleOption.textContent = `Female Voice: ${femaleVoiceData.name}`;
                voiceSelect.appendChild(femaleOption);
            } else {
                 // Fallback if only one distinct voice could be found
                 const fallbackOption = document.createElement('option');
                 fallbackOption.value = maleVoiceData.name; 
                 fallbackOption.textContent = `Female Voice (Note: Using ${maleVoiceData.name})`;
                 voiceSelect.appendChild(fallbackOption);
            }
            
            // Set the dropdown value to the default voice
            voiceSelect.value = selectedVoice.name;
        }

        // Event handler for when voices are ready (critical for Chrome)
        if (synth.onvoiceschanged !== undefined) {
            synth.onvoiceschanged = populateVoiceList;
        } else {
            populateVoiceList(); 
        }

        voiceSelect.addEventListener('change', () => {
            const voiceName = voiceSelect.value;
            selectedVoice = availableVoices.find(v => v.name === voiceName);
        });

        function speak(text) {
            if (synth.speaking || text === lastSpokenText || !selectedVoice) return;
            isSpeaking = true;
            
            const utterThis = new SpeechSynthesisUtterance(text);
            utterThis.pitch = 1.0;
            utterThis.rate = 0.88; // Slightly slower for a more natural delivery
            utterThis.voice = selectedVoice; 
            
            utterThis.onend = () => {
                isSpeaking = false;
                lastSpokenText = text;
            };
            synth.speak(utterThis);
        }

        // --- GEOMETRY UTILITIES (UNCHANGED) ---

        function distance(lm1, lm2) {
            return Math.sqrt(
                Math.pow(lm1.x - lm2.x, 2) +
                Math.pow(lm1.y - lm2.y, 2) +
                Math.pow(lm1.z - lm2.z, 2)
            );
        }
        
        function isFingerExtended(landmarks, tipIndex) {
            const tip = landmarks[tipIndex];
            const mcp = landmarks[tipIndex - 3];
            return tip.y < mcp.y - 0.05;
        }

        // --- SIGN RECOGNITION LOGIC (UNCHANGED) ---

        function getSignFromLandmarks(landmarks) {
            const isThumbOpen = isFingerExtended(landmarks, L_THUMB_TIP);
            const isIndexOpen = isFingerExtended(landmarks, L_INDEX_TIP);
            const isMiddleOpen = isFingerExtended(landmarks, L_MIDDLE_TIP);
            const isRingOpen = isFingerExtended(landmarks, L_RING_TIP);
            const isPinkyOpen = isFingerExtended(landmarks, L_PINKY_TIP);
            
            // 1. Hello (Open Hand)
            if (isThumbOpen && isIndexOpen && isMiddleOpen && isRingOpen && isPinkyOpen) {
                confidenceLevel = 0.9;
                currentShapeTarget = 'sphere';
                return 'Hello';
            }

            // 2. I Love You (ILY - Index, Pinky, Thumb extended)
            if (isIndexOpen && isPinkyOpen && isThumbOpen && !isMiddleOpen && !isRingOpen) {
                confidenceLevel = 0.8;
                currentShapeTarget = 'heart';
                return 'I Love You ';
            }
            
            // 3. No / Fist (All fingers curled)
            if (!isThumbOpen && !isIndexOpen && !isMiddleOpen && !isRingOpen && !isPinkyOpen) {
                confidenceLevel = 0.7;
                currentShapeTarget = 'small_sphere';
                return 'No';
            }

            // 4. Index Finger (Request/Help - Index extended only)
            if (isIndexOpen && !isThumbOpen && !isMiddleOpen && !isRingOpen && !isPinkyOpen) {
                confidenceLevel = 0.85;
                currentShapeTarget = 'saturn';
                return 'Help / Pointing';
            }

            confidenceLevel = 0.0;
            currentShapeTarget = 'chaos';
            return 'Unclear';
        }

        // --- MEDIAPIPE HANDLER (UNCHANGED) ---

        function onResults(results) {
            if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
                handLandmarks = results.multiHandLandmarks[0];
                isHandPresent = true;
                
                const newSign = getSignFromLandmarks(handLandmarks);
                const pinchDistance = distance(handLandmarks[L_INDEX_TIP], handLandmarks[L_THUMB_TIP]);

                if (newSign !== 'Unclear' && newSign === lastStableSign) {
                    if (!recognitionTimer) {
                        recognitionTimer = setTimeout(() => {
                            recognizedSign = newSign;
                            signEl.innerText = recognizedSign;
                            signEl.className = 'recognized';
                        }, RECOGNITION_HOLD_TIME);
                    }
                } else {
                    clearTimeout(recognitionTimer);
                    recognitionTimer = null;
                    lastStableSign = newSign;
                    if (recognizedSign === 'Unclear') {
                        signEl.innerText = newSign;
                        signEl.className = newSign === 'Unclear' ? 'unclear' : 'status';
                    }
                }
                
                if (recognizedSign !== 'Unclear' && pinchDistance < CONFIRM_GESTURE_THRESHOLD && !isSpeaking) {
                    outputEl.innerText = `Speaking: ${recognizedSign}...`;
                    speak(recognizedSign);
                    recognizedSign = 'Unclear';
                    lastStableSign = 'Unclear';
                    signEl.innerText = 'Confirmed';
                }

                statusEl.innerText = 'Listening & Tracking';
                statusEl.className = 'recognized';

            } else {
                clearTimeout(recognitionTimer);
                recognitionTimer = null;
                isHandPresent = false;
                recognizedSign = 'Unclear';
                lastStableSign = 'Unclear';
                statusEl.innerText = 'Waiting for Hand';
                statusEl.className = 'status';
                if (!isSpeaking) {
                    outputEl.innerText = '';
                }
            }
        }

        const hands = new Hands({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`});
        hands.setOptions({ maxNumHands: 1, modelComplexity: 1, minDetectionConfidence: 0.5, minTrackingConfidence: 0.5 });
        hands.onResults(onResults);

        const videoElement = document.getElementById('input_video');
        
        // --- MOBILE-READY CAMERA SETUP ---
        const cameraUtils = new Camera(videoElement, {
            onFrame: async () => { await hands.send({image: videoElement}); },
            width: CAM_WIDTH, 
            height: CAM_HEIGHT,
            // Use environment camera on mobile by default
            facingMode: 'user' 
        });
        cameraUtils.start();


        // --- THREE.JS SETUP AND ANIMATION (UNCHANGED) ---
        
        const scene = new THREE.Scene();
        scene.fog = new THREE.FogExp2(0x000000, 0.002);
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        camera.position.z = 50;
        const renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setPixelRatio(window.devicePixelRatio);
        document.body.appendChild(renderer.domElement);

        // Particle Data
        const geometry = new THREE.BufferGeometry();
        const positions = new Float32Array(PARTICLE_COUNT * 3);
        const targets = new Float32Array(PARTICLE_COUNT * 3);
        const colors = new Float32Array(PARTICLE_COUNT * 3);

        for (let i = 0; i < PARTICLE_COUNT; i++) {
            positions[i * 3] = (Math.random() - 0.5) * 100;
            positions[i * 3 + 1] = (Math.random() - 0.5) * 100;
            positions[i * 3 + 2] = (Math.random() - 0.5) * 100;
            targets[i*3] = positions[i*3];
            targets[i*3+1] = positions[i*3+1];
            targets[i*3+2] = positions[i*3+2];
            colors[i*3] = colors[i*3+1] = colors[i*3+2] = 0.5;
        }

        geometry.setAttribute('position', new THREE.BufferAttribute(positions, 3));
        geometry.setAttribute('color', new THREE.BufferAttribute(colors, 3));

        const getSprite = () => {
            const canvas = document.createElement('canvas');
            canvas.width = 32; canvas.height = 32;
            const context = canvas.getContext('2d');
            const gradient = context.createRadialGradient(16, 16, 0, 16, 16, 16);
            gradient.addColorStop(0, 'rgba(255,255,255,1)');
            gradient.addColorStop(0.5, 'rgba(255,255,255,0.2)');
            gradient.addColorStop(1, 'rgba(0,0,0,0)');
            context.fillStyle = gradient;
            context.fillRect(0, 0, 32, 32);
            const texture = new THREE.Texture(canvas);
            texture.needsUpdate = true;
            return texture;
        };

        const material = new THREE.PointsMaterial({
            size: 0.6,
            map: getSprite(),
            vertexColors: true,
            blending: THREE.AdditiveBlending,
            depthWrite: false,
            transparent: true,
            opacity: 0.8
        });
        const particles = new THREE.Points(geometry, material);
        scene.add(particles);

        // --- SHAPE GENERATORS (UNCHANGED) ---
        function setTargetShape(shapeType) {
            for (let i = 0; i < PARTICLE_COUNT; i++) {
                const idx = i * 3;
                let x, y, z;
                let r, theta, phi;

                if (shapeType === 'sphere') {
                    r = 15;
                    theta = Math.random() * Math.PI * 2;
                    phi = Math.acos((Math.random() * 2) - 1);
                    x = r * Math.sin(phi) * Math.cos(theta);
                    y = r * Math.sin(phi) * Math.sin(theta);
                    z = r * Math.cos(phi);
                } else if (shapeType === 'heart') {
                    r = Math.random() * 2; 
                    theta = Math.random() * Math.PI * 2;
                    const hx = 16 * Math.pow(Math.sin(theta), 3);
                    const hy = 13 * Math.cos(theta) - 5 * Math.cos(2*theta) - 2 * Math.cos(3*theta) - Math.cos(4*theta);
                    x = hx * 0.8 + (Math.random() - 0.5) * r;
                    y = hy * 0.8 + (Math.random() - 0.5) * r;
                    z = (Math.random() - 0.5) * 10;
                } else if (shapeType === 'saturn') {
                    const isRing = Math.random() > 0.6;
                    if(isRing) {
                        r = 20 + Math.random() * 10;
                        theta = Math.random() * Math.PI * 2;
                        x = r * Math.cos(theta);
                        z = r * Math.sin(theta);
                        y = (Math.random() - 0.5) * 2;
                    } else {
                        r = 10;
                        theta = Math.random() * Math.PI * 2;
                        phi = Math.acos((Math.random() * 2) - 1);
                        x = r * Math.sin(phi) * Math.cos(theta);
                        y = r * Math.sin(phi) * Math.sin(theta);
                        z = r * Math.cos(phi);
                    }
                } else if (shapeType === 'chaos' || shapeType === 'small_sphere') {
                    r = shapeType === 'chaos' ? 50 : 8;
                    x = (Math.random() - 0.5) * r;
                    y = (Math.random() - 0.5) * r;
                    z = (Math.random() - 0.5) * r;
                }

                targets[idx] = x;
                targets[idx+1] = y;
                targets[idx+2] = z;
            }
        }
        setTargetShape(currentShapeTarget);

        // --- ANIMATION LOOP (UNCHANGED) ---
        const clock = new THREE.Clock();
        let lastShape = currentShapeTarget;

        function animate() {
            requestAnimationFrame(animate);
            const delta = clock.getDelta();
            
            const positionsArr = geometry.attributes.position.array;
            const colorsArr = geometry.attributes.color.array;

            if (lastShape !== currentShapeTarget) {
                setTargetShape(currentShapeTarget);
                lastShape = currentShapeTarget;
            }

            let expansionFactor = 1.0;
            let morphSpeed = 0.05;
            let targetR = 0.5, targetG = 0.5, targetB = 0.5;

            if (isSpeaking) {
                targetR = 0.5; 
                targetG = 1.0; 
                targetB = 1.0;
                expansionFactor = 2.0;
                morphSpeed = 0.2;
            } else if (isHandPresent) {
                targetR = 1.0 - confidenceLevel;
                targetG = confidenceLevel;
                targetB = 0.2 + confidenceLevel * 0.8;
                expansionFactor = THREE.MathUtils.mapLinear(pinchDistance, 0.0, 1.0, 1.0, 1.5);
                morphSpeed = 0.1;
            } else {
                targetR = targetG = targetB = 0.1;
                expansionFactor = 1.0;
                morphSpeed = 0.01;
                particles.position.x = 0; 
                particles.position.y = 0;
            }

            // Morphing and Color Update
            for (let i = 0; i < PARTICLE_COUNT; i++) {
                const idx = i * 3;

                const tx = targets[idx] * expansionFactor;
                const ty = targets[idx+1] * expansionFactor;
                const tz = targets[idx+2] * expansionFactor;

                positionsArr[idx] += (tx - positionsArr[idx]) * morphSpeed;
                positionsArr[idx+1] += (ty - positionsArr[idx+1]) * morphSpeed;
                positionsArr[idx+2] += (tz - positionsArr[idx+2]) * morphSpeed;

                colorsArr[idx] += (targetR - colorsArr[idx]) * 0.1;
                colorsArr[idx+1] += (targetG - colorsArr[idx+1]) * 0.1;
                colorsArr[idx+2] += (targetB - colorsArr[idx+2]) * 0.1;
            }

            geometry.attributes.position.needsUpdate = true;
            geometry.attributes.color.needsUpdate = true;
            particles.rotation.y += delta * 0.05; 

            renderer.render(scene, camera);
        }

        animate();

        // --- MOBILE-FRIENDLY RESIZE HANDLER ---
        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        });
    </script>
</body>
</html>
